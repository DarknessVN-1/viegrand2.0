import Groq from "groq-sdk";

const GROQ_API_KEY = "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";
const groq = new Groq({ apiKey: GROQ_API_KEY });

export class GroqService {
  static systemPrompt = `
B·∫°n l√† tr·ª£ l√Ω ph√¢n t√≠ch y√™u c·∫ßu ng∆∞·ªùi d√πng.
Ph√¢n t√≠ch v√† tr·∫£ v·ªÅ m·ªôt trong hai ƒë·ªãnh d·∫°ng JSON d∆∞·ªõi ƒë√¢y:

1. N·∫øu l√† L·ªÜNH ƒëi·ªÅu h∆∞·ªõng ho·∫∑c h√†nh ƒë·ªông:
{
  "type": "command",
  "command": "<t√™n m√†n h√¨nh>",
  "action": "<h√†nh ƒë·ªông>",
  "confidence": 1.0
}

2. N·∫øu l√† C√ÇU H·ªéI ho·∫∑c TR√í CHUY·ªÜN:
{
  "type": "conversation", 
  "text": "<c√¢u tr·∫£ l·ªùi>"
}

C√ÅC M√ÄN H√åNH C·ª¶A ·ª®NG D·ª§NG:
- ElderlyHome: m√†n h√¨nh ch√≠nh
- Video: xem video
- Truy·ªán: ƒë·ªçc truy·ªán
- MiniGame: ch∆°i game
- RadioScreen: nghe radio
- ExerciseSelection: t·∫≠p th·ªÉ d·ª•c

V√ç D·ª§:
Input: "t√¥i mu·ªën ƒë·ªçc truy·ªán" 
Output: {"type": "command", "command": "Truy·ªán", "action": "navigate", "confidence": 1.0}

Input: "t√™n b·∫°n l√† g√¨"
Output: {"type": "conversation", "text": "T√¥i l√† Viebot, tr·ª£ l√Ω ·∫£o c·ªßa ·ª©ng d·ª•ng Viegrand."}

Input: "b·∫°n c√≥ th·ªÉ l√†m g√¨"
Output: {"type": "conversation", "text": "T√¥i c√≥ th·ªÉ gi√∫p b·∫°n xem video, ƒë·ªçc truy·ªán, ch∆°i game, nghe radio v√† t·∫≠p th·ªÉ d·ª•c. B·∫°n mu·ªën l√†m g√¨?"}

CH√ö √ù: 
- LU√îN tr·∫£ v·ªÅ JSON h·ª£p l·ªá
- KH√îNG th√™m text ngo√†i JSON
- KH√îNG th√™m gi·∫£i th√≠ch
- CH·ªà tr·∫£ v·ªÅ m·ªôt trong hai ƒë·ªãnh d·∫°ng tr√™n`;

  static async analyzeCommand(text) {
    try {
      console.log('üîµ ==== START GROQ ANALYSIS ====');
      console.log('üìù Input:', text);

      const chatCompletion = await groq.chat.completions.create({
        messages: [
          {
            role: "system",
            content: this.systemPrompt
          },
          {
            role: "user",
            content: text
          }
        ],
        model: "llama3-70b-8192",
        temperature: 0.1, // Reduced temperature for more consistent output
        max_tokens: 200,
        top_p: 0.9,
      });

      console.log('üì° Raw Groq Response:', JSON.stringify(chatCompletion, null, 2));

      if (!chatCompletion.choices?.[0]?.message?.content) {
        throw new Error('Invalid API response structure');
      }

      const rawContent = chatCompletion.choices[0].message.content.trim();
      console.log('üìù Raw content:', rawContent);

      try {
        const result = JSON.parse(rawContent);
        console.log('‚ú® Parsed Result:', JSON.stringify(result, null, 2));
        return result;
      } catch (parseError) {
        console.error('‚ùå JSON Parse error:', parseError);
        // If parsing fails, try to extract JSON from the string
        const jsonMatch = rawContent.match(/\{.*\}/s);
        if (jsonMatch) {
          const extractedJson = jsonMatch[0];
          console.log('üîç Extracted JSON:', extractedJson);
          return JSON.parse(extractedJson);
        }
        throw parseError;
      }

    } catch (error) {
      console.error('‚ùå Groq API Error:', error);
      console.error('Error details:', {
        name: error.name,
        message: error.message,
        stack: error.stack
      });
      return null;
    } finally {
      console.log('üîµ ==== END GROQ ANALYSIS ====');
    }
  }

  static async generateResponse(context) {
    try {
      console.log('üéØ Generating response for context:', context);

      const chatCompletion = await groq.chat.completions.create({
        messages: [
          {
            role: "system",
            content: this.systemPrompt
          },
          {
            role: "user",
            content: `T·∫°o c√¢u tr·∫£ l·ªùi cho t√¨nh hu·ªëng: ${JSON.stringify(context)}`
          }
        ],
        model: "llama3-70b-8192",
        temperature: 0.5,
        max_tokens: 300,
        top_p: 0.9,
      });

      const response = chatCompletion.choices[0]?.message?.content;
      console.log('üì• Generated Response:', response);
      
      return response || null;
    } catch (error) {
      console.error('‚ùå Response generation failed:', error);
      return null;
    }
  }

  static async handleGeneralChat(text) {
    try {
      const chatCompletion = await groq.chat.completions.create({
        messages: [
          {
            role: "system",
            content: "B·∫°n l√† Viebot - tr·ª£ l√Ω ·∫£o th√¢n thi·ªán. H√£y tr·∫£ l·ªùi ng·∫Øn g·ªçn, ƒë∆°n gi·∫£n v√† th√¢n thi·ªán."
          },
          {
            role: "user",
            content: text
          }
        ],
        model: "llama3-70b-8192",
        temperature: 0.7,
        max_tokens: 200,
      });

      return chatCompletion.choices[0]?.message?.content || 'Xin l·ªói, t√¥i kh√¥ng hi·ªÉu. B·∫°n c√≥ th·ªÉ n√≥i r√µ h∆°n ƒë∆∞·ª£c kh√¥ng?';
    } catch (error) {
      console.error('‚ùå Chat failed:', error);
      return 'Xin l·ªói, ƒë√£ c√≥ l·ªói x·∫£y ra. Vui l√≤ng th·ª≠ l·∫°i.';
    }
  }

  static async cleanTranscription(text) {
    try {
      console.log('üßπ Cleaning transcription:', text);

      const chatCompletion = await groq.chat.completions.create({
        messages: [
          {
            role: "system",
            content: `B·∫°n l√† tr·ª£ l√Ω x·ª≠ l√Ω vƒÉn b·∫£n. H√£y:
            1. Lo·∫°i b·ªè c√°c t·ª´ nhi·ªÖu nh∆∞ "ƒëang l·∫≠n nghe", "ƒëang l·∫Øng nghe"
            2. S·ª≠a c√°c l·ªói ch√≠nh t·∫£ nh·∫π
            3. Tr·∫£ v·ªÅ m·ªôt c√¢u ho√†n ch·ªânh v√† r√µ r√†ng
            4. KH√îNG th√™m b·∫•t k·ª≥ ph√¢n t√≠ch hay tr·∫£ l·ªùi n√†o
            Ch·ªâ tr·∫£ v·ªÅ c√¢u ƒë√£ ƒë∆∞·ª£c l√†m s·∫°ch.`
          },
          {
            role: "user",
            content: text
          }
        ],
        model: "llama3-70b-8192",
        temperature: 0.3,
        max_tokens: 100
      });

      const cleanedText = chatCompletion.choices[0]?.message?.content;
      console.log('‚ú® Cleaned result:', cleanedText);
      
      return cleanedText;
    } catch (error) {
      console.error('‚ùå Text cleaning failed:', error);
      return text; // Return original text if cleaning fails
    }
  }
}
